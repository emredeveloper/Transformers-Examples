import torch
import torch.nn as nn
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.text import Text
from rich import print as rprint
from rich import box

# Initialize rich console
console = Console()

def print_section(title, color="cyan"):
    """Print a section header with rich formatting"""
    console.rule(f"[bold {color}]{title}", style=color)

# --- 1. Daha Derin bir PyTorch Modeli TanÄ±mla ---
class DeepMLP(nn.Module):
    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.1):
        """
        Derin bir Ã§ok katmanlÄ± algÄ±layÄ±cÄ± (MLP) modeli
        
        Args:
            input_dim: GiriÅŸ boyutu
            hidden_dims: Gizli katman boyutlarÄ±nÄ± iÃ§eren liste
            output_dim: Ã‡Ä±kÄ±ÅŸ boyutu
            dropout_rate: Dropout oranÄ± (varsayÄ±lan: 0.1)
        """
        super().__init__()
        self.layers = nn.ModuleList()
        
        # GiriÅŸ katmanÄ±
        prev_dim = input_dim
        
        # Gizli katmanlarÄ± oluÅŸtur
        for i, hidden_dim in enumerate(hidden_dims):
            self.layers.append(nn.Linear(prev_dim, hidden_dim))
            self.layers.append(nn.BatchNorm1d(hidden_dim))
            self.layers.append(nn.ReLU())
            self.layers.append(nn.Dropout(dropout_rate))
            prev_dim = hidden_dim
            
        # Ã‡Ä±kÄ±ÅŸ katmanÄ±
        self.output_layer = nn.Linear(prev_dim, output_dim)
        
        # AÄŸÄ±rlÄ±k baÅŸlatma
        self._init_weights()
        
        # Model bilgilerini gÃ¶ster
        self._print_model_info(input_dim, hidden_dims, output_dim, dropout_rate)
    
    def _init_weights(self):
        """AÄŸÄ±rlÄ±klarÄ± Xavier/Glorot baÅŸlatma yÃ¶ntemiyle baÅŸlat"""
        for layer in self.layers:
            if isinstance(layer, nn.Linear):
                nn.init.xavier_uniform_(layer.weight)
                if layer.bias is not None:
                    nn.init.zeros_(layer.bias)
        nn.init.xavier_uniform_(self.output_layer.weight)
        if self.output_layer.bias is not None:
            nn.init.zeros_(self.output_layer.bias)
    
    def _print_model_info(self, input_dim, hidden_dims, output_dim, dropout_rate):
        """Model yapÄ±sÄ± hakkÄ±nda bilgi gÃ¶ster"""
        total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        info_table = Table(show_header=False, box=box.ROUNDED, show_edge=False)
        info_table.add_column("Ã–zellik", style="cyan", no_wrap=True)
        info_table.add_column("DeÄŸer", style="green")
        
        info_table.add_row("Model TÃ¼rÃ¼", "Derin Ã‡ok KatmanlÄ± AlgÄ±layÄ±cÄ± (MLP)")
        info_table.add_row("Toplam Parametre", f"{total_params:,}")
        info_table.add_row("GiriÅŸ Boyutu", str(input_dim))
        info_table.add_row("Gizli Katmanlar", " â†’ ".join(map(str, hidden_dims)))
        info_table.add_row("Ã‡Ä±kÄ±ÅŸ Boyutu", str(output_dim))
        info_table.add_row("Dropout OranÄ±", str(dropout_rate))
        
        console.print(Panel(
            info_table,
            title="[bold green]Model YapÄ±landÄ±rmasÄ±[/]",
            border_style="green",
            padding=(1, 2)
        ))
    
    def forward(self, x):
        """Ä°leri yayÄ±lÄ±m"""
        # Gizli katmanlardan geÃ§ir
        for layer in self.layers:
            x = layer(x)
            
        # Ã‡Ä±kÄ±ÅŸ katmanÄ±
        x = self.output_layer(x)
        return x

# --- Kanca (Hook) iÃ§in Global Depolama ve Durum YÃ¶netimi ---
# GerÃ§ek bir uygulamada bu durumu daha temiz yÃ¶netmek istersiniz (Ã¶rneÄŸin bir sÄ±nÄ±f iÃ§inde).
hook_state = {
    "captured_activation": None,    # Yakalanan aktivasyonu saklamak iÃ§in
    "is_intervention_mode": False,  # MÃ¼dahale modunda olup olmadÄ±ÄŸÄ±mÄ±zÄ± belirtir
    "neuron_to_modify_idx": 0,    # Hangi nÃ¶ronun aktivasyonuna mÃ¼dahale edileceÄŸi
    "intervention_value": 0.0     # MÃ¼dahale edilecek yeni deÄŸer
}

# --- 2. AktivasyonlarÄ± Yakalamak ve DeÄŸiÅŸtirmek iÃ§in bir Kanca (Hook) Uygula ---
def activation_hook_fn(module, input_args, output_tensor):
    """
    Bu bir PyTorch ileri (forward) kancasÄ±dÄ±r.
    EÄŸer 'is_intervention_mode' False ise, katmanÄ±n Ã§Ä±kÄ±ÅŸ aktivasyonunu yakalar.
    EÄŸer 'is_intervention_mode' True ise, belirtilen bir nÃ¶ronun aktivasyonunu deÄŸiÅŸtirir.
    """
    global hook_state

    if not hook_state["is_intervention_mode"]:
        # Normal (yakalama) mod: Aktivasyonu sakla
        hook_state["captured_activation"] = output_tensor.clone().detach()
        # print(f"Kanca (Yakalama): {module} Ã§Ä±kÄ±ÅŸÄ± yakalandÄ±: {hook_state['captured_activation']}")
        return None # Ã‡Ä±kÄ±ÅŸÄ± deÄŸiÅŸtirme, orijinali kullanÄ±lsÄ±n
    else:
        # MÃ¼dahale modu: Aktivasyonu deÄŸiÅŸtir
        modified_output = output_tensor.clone() # DeÄŸiÅŸiklik yapmadan Ã¶nce klonla!

        # Ã–rneÄŸin, ilk nÃ¶ronun (batch_size=1 varsayÄ±mÄ±yla) aktivasyonunu deÄŸiÅŸtir
        # output_tensor'un ÅŸekli [batch_size, num_features] beklenir
        if modified_output.ndim == 2 and modified_output.shape[0] == 1: # [1, hidden_dim] gibi
            neuron_idx = hook_state["neuron_to_modify_idx"]
            if 0 <= neuron_idx < modified_output.shape[1]:
                # print(f"Kanca (MÃ¼dahale): {module} NÃ¶ron {neuron_idx} orijinal deÄŸeri: {modified_output[0, neuron_idx]}")
                modified_output[0, neuron_idx] = hook_state["intervention_value"]
                # print(f"Kanca (MÃ¼dahale): {module} NÃ¶ron {neuron_idx} yeni deÄŸeri: {modified_output[0, neuron_idx]}")
                hook_state["captured_activation"] = modified_output.clone().detach() # DeÄŸiÅŸtirilmiÅŸ aktivasyonu da sakla
                return modified_output # DeÄŸiÅŸtirilmiÅŸ aktivasyonu dÃ¶ndÃ¼r
            else:
                print(f"UyarÄ±: NÃ¶ron indeksi {neuron_idx} sÄ±nÄ±rlar dÄ±ÅŸÄ±nda.")
                return None # Bir sorun varsa orijinali dÃ¶ndÃ¼r
        else:
            print(f"UyarÄ±: Kanca, [1, num_features] ÅŸeklinde aktivasyon bekliyordu, gelen: {modified_output.shape}")
            return None # Bir sorun varsa orijinali dÃ¶ndÃ¼r

# --- Model ve Veri Kurulumu ---
input_dim = 10
hidden_dims = [64, 32, 16]  # Daha derin mimari
output_dim = 2
dropout_rate = 0.1

# Modeli oluÅŸtur
model = DeepMLP(input_dim, hidden_dims, output_dim, dropout_rate)

# KullanÄ±labilir cihazÄ± belirle (GPU varsa onu kullan)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Model Ã¶zetini gÃ¶ster
console.print(f"\n[bold]Model {device} cihazÄ±na yÃ¼klendi.[/]")
console.print(f"EÄŸitilebilir parametre sayÄ±sÄ±: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")

# TÃ¼m ReLU katmanlarÄ±na kancalarÄ± kaydet
hook_handles = []
for i, layer in enumerate(model.layers):
    if isinstance(layer, nn.ReLU):
        handle = layer.register_forward_hook(activation_hook_fn)
        hook_handles.append(handle)
        print(f"ReLU katmanÄ±na kanca eklendi: {i}")

if not hook_handles:
    raise ValueError("Modelde hiÃ§ ReLU katmanÄ± bulunamadÄ±!")

# Rastgele bir girdi verisi oluÅŸtur (basitlik iÃ§in batch_size=1)
dummy_input = torch.randn(1, input_dim).to(device)

# Girdi verisi hakkÄ±nda bilgi
input_info = Table(show_header=True, header_style="bold magenta", box=box.ROUNDED)
input_info.add_column("Ã–zellik", style="cyan")
input_info.add_column("DeÄŸer", style="green")
input_info.add_row("Girdi Boyutu", f"{tuple(dummy_input.shape)}")
input_info.add_row("Min DeÄŸer", f"{dummy_input.min().item():.4f}")
input_info.add_row("Maksimum DeÄŸer", f"{dummy_input.max().item():.4f}")
input_info.add_row("Ortalama", f"{dummy_input.mean().item():.4f}")
input_info.add_row("Standart Sapma", f"{dummy_input.std().item():.4f}")

console.print(Panel(
    input_info,
    title="[bold blue]Girdi Verisi Ä°statistikleri[/]",
    border_style="blue",
    padding=(1, 2)
))

# Ä°lk 5 Ã¶zelliÄŸi gÃ¶ster
input_sample = Table(show_header=True, header_style="bold magenta", box=box.ROUNDED)
input_sample.add_column("Ã–zellik Ä°ndeksi", style="cyan")
input_sample.add_column("DeÄŸer", style="green")

for i, val in enumerate(dummy_input.squeeze().cpu().numpy()[:5]):
    input_sample.add_row(f"{i}", f"{val:.6f}")

console.print(Panel(
    input_info,
    title="[bold blue]Girdi Verisi (Ä°lk 5 Ã–zellik)[/]",
    border_style="blue",
    padding=(1, 2)
))
print_section("ğŸ”§ Model ve Veri Kurulumu")
console.print(f"[bold]Model YapÄ±sÄ±:[/] [cyan]Input: {input_dim}[/] â†’ [green]Hidden: {hidden_dim}[/] â†’ [yellow]Output: {output_dim}[/]")
console.print(f"[bold]Girdi Verisi:[/] {dummy_input.squeeze().tolist()[:5]}... [dim](ilk 5 Ã¶zellik gÃ¶steriliyor)[/dim]\n")

# --- 3. "Temiz Ã‡alÄ±ÅŸtÄ±rma": Temel aktivasyonlarÄ± ve Ã§Ä±ktÄ±yÄ± al ---
print_section("ğŸ” Temiz Ã‡alÄ±ÅŸtÄ±rma (MÃ¼dahalesiz)")

hook_state["is_intervention_mode"] = False
with torch.no_grad():
    original_output = model(dummy_input)
    clean_hidden_activation = hook_state["captured_activation"]

# Gizli katman aktivasyonlarÄ±nÄ± gÃ¶steren tablo
table = Table(show_header=True, header_style="bold magenta", box=box.ROUNDED)
table.add_column("NÃ¶ron", style="dim", width=12)
table.add_column("Aktivasyon DeÄŸeri", justify="right")

for i, val in enumerate(clean_hidden_activation.squeeze().tolist()):
    table.add_row(f"NÃ¶ron {i}", f"{val:.4f}")

console.print(Panel.fit(
    table,
    title="[bold]Gizli Katman AktivasyonlarÄ± (ReLU SonrasÄ±)",
    border_style="green",
    padding=(1, 2)
))

console.print(f"\n[bold]Model Ã‡Ä±ktÄ±sÄ±:[/] {original_output.squeeze().tolist()}")
console.rule(style="dim")

# --- 4. "MÃ¼dahale Ã‡alÄ±ÅŸtÄ±rmasÄ±": Bir aktivasyonu deÄŸiÅŸtir ve etkiyi gÃ¶r ---
print_section("ğŸ”§ MÃ¼dahale Ã‡alÄ±ÅŸtÄ±rmasÄ±")

# MÃ¼dahale ayarlarÄ±
neuron_idx = 0
new_value = 10.0

hook_state["is_intervention_mode"] = True
hook_state["neuron_to_modify_idx"] = neuron_idx
hook_state["intervention_value"] = new_value

with torch.no_grad():
    intervened_output = model(dummy_input)
    intervened_hidden_activation = hook_state["captured_activation"]

# MÃ¼dahale Ã¶zeti
console.print(f"[bold]MÃ¼dahale DetaylarÄ±:[/]")
console.print(f"  â€¢ [yellow]Hedef NÃ¶ron:[/] [bold]{neuron_idx}[/]")
console.print(f"  â€¢ [yellow]Yeni DeÄŸer:[/] [bold]{new_value}[/]")

# MÃ¼dahale edilmiÅŸ aktivasyonlar tablosu
modified_table = Table(show_header=True, header_style="bold magenta", box=box.ROUNDED)
modified_table.add_column("NÃ¶ron", style="dim", width=12)
modified_table.add_column("Ã–nceki DeÄŸer", justify="right")
modified_table.add_column("Yeni DeÄŸer", justify="right")
modified_table.add_column("Durum", justify="center")

for i, (orig, new) in enumerate(zip(
    clean_hidden_activation.squeeze().tolist(),
    intervened_hidden_activation.squeeze().tolist()
)):
    modified = i == neuron_idx
    status = "[bold red]âœ— DeÄŸiÅŸtirildi" if modified else "[green]âœ“ AynÄ±"
    orig_val = f"[strike dim]{orig:.4f}[/]" if modified else f"{orig:.4f}"
    new_val = f"[bold red]{new:.4f}" if modified else f"{new:.4f}"
    
    modified_table.add_row(
        f"NÃ¶ron {i}",
        orig_val,
        new_val,
        status
    )

console.print(Panel.fit(
    modified_table,
    title="[bold]Gizli Katman KarÅŸÄ±laÅŸtÄ±rmasÄ±",
    border_style="yellow",
    padding=(1, 2)
))

console.print(f"\n[bold]Yeni Model Ã‡Ä±ktÄ±sÄ±:[/] {intervened_output.squeeze().tolist()}")
console.rule(style="dim")

# --- 5. KarÅŸÄ±laÅŸtÄ±r ---
print_section("ğŸ“Š SonuÃ§larÄ±n KarÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±")

# Ã‡Ä±ktÄ± karÅŸÄ±laÅŸtÄ±rma tablosu
output_table = Table(show_header=True, header_style="bold magenta", box=box.ROUNDED)
output_table.add_column("Ã‡Ä±ktÄ± NÃ¶ronu", style="dim", width=12)
output_table.add_column("Orijinal DeÄŸer", justify="right")
output_table.add_column("Yeni DeÄŸer", justify="right")
output_table.add_column("Fark", justify="right")

orig_outputs = original_output.squeeze().tolist()
new_outputs = intervened_output.squeeze().tolist()
diffs = torch.abs(original_output - intervened_output).squeeze().tolist()

for i, (orig, new, diff) in enumerate(zip(orig_outputs, new_outputs, diffs)):
    diff_style = "[red]" if diff > 0.1 else "[green]"
    output_table.add_row(
        f"Ã‡Ä±ktÄ± {i}",
        f"{orig:.6f}",
        f"{new:.6f}",
        f"{diff_style}{diff:.6f}"
    )

console.print(Panel.fit(
    output_table,
    title="[bold]Ã‡Ä±ktÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±",
    border_style="blue",
    padding=(1, 2)
))

# Ã–zet istatistikler
console.print("\n[bold]ğŸ“ˆ Ã–zet Ä°statistikler:[/]")
console.print(f"  â€¢ [yellow]Toplam Mutlak Fark:[/] {torch.sum(torch.abs(original_output - intervened_output)):.6f}")
console.print(f"  â€¢ [yellow]Maksimum Fark:[/] {torch.max(torch.abs(original_output - intervened_output)):.6f}")
console.print(f"  â€¢ [yellow]Ortalama Mutlak Fark:[/] {torch.mean(torch.abs(original_output - intervened_output)):.6f}")

# Kanca temizliÄŸi hakkÄ±nda bilgi
console.print("\n[dim]Not: Kanca baÅŸarÄ±yla kaldÄ±rÄ±ldÄ±.[/dim]")


# KancayÄ± iÅŸiniz bittiÄŸinde kaldÄ±rmayÄ± unutmayÄ±n,
# Ã¶zellikle bir notebook'ta hÃ¼creleri tekrar tekrar Ã§alÄ±ÅŸtÄ±rÄ±yorsanÄ±z.
hook_handle.remove()