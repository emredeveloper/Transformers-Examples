# Transformers Examples

Bu repository, modern derin Ã¶ÄŸrenme modellerinin farklÄ± yÃ¶nlerini gÃ¶steren Transformers kÃ¼tÃ¼phanesi kullanÄ±larak geliÅŸtirilmiÅŸ Ã§eÅŸitli Ã¶rnekler ve implementasyonlar iÃ§erir. Dil modelleri, vision transformers, multimodal modeller ve daha fazlasÄ±nÄ± kapsar.

## ğŸ“ Repository YapÄ±sÄ±

### Ana Dizinler

- **`Architecture/`** - **YENÄ°!** RoPE (Rotary Position Embedding) karÅŸÄ±laÅŸtÄ±rmalarÄ± ve transformer mimarisi Ã¶rnekleri
- **`Genel-1/`** - Temel transformer implementasyonlarÄ± ve konfigÃ¼rasyon Ã¶rnekleri
- **`Genel-2/`** - GeliÅŸmiÅŸ transformer modelleri (vision transformers ve multimodal Ã¶rnekler)
- **`Genel-3/`** - Ek transformer varyantlarÄ± ve deneyler
- **`Genel-4/`** - Performans karÅŸÄ±laÅŸtÄ±rmalarÄ± ve fine-tuning Ã¶rnekleri
- **`Genel-5/`** - Ä°leri teknikler ve model optimizasyonlarÄ±
- **`Multi Modal/`** - Video, ses ve metin iÃ§in multimodal transformer implementasyonlarÄ±
- **`Vision Transformers/`** - Vision transformer modelleri ve uygulamalarÄ±
- **`Time series - Transformers/`** - Transformer modelleri kullanarak zaman serisi analizi
- **`Tokenizer/`** - Ã–zel tokenizer implementasyonlarÄ± ve eÄŸitimi
- **`llama/`** - LLaMA model implementasyonu ve utilities
- **`Qwen3/`** - Qwen 3 model Ã¶rnekleri ve kullanÄ±mÄ±
- **`finetuned-llm/`** - Fine-tuned dil modeli checkpoint'leri
- **`archive/`** - MMLU benchmark sonuÃ§larÄ± ve arÅŸivlenmiÅŸ dosyalar

### Ã–nemli Dosyalar

- **`test-time-scaling.py`** - Dil modelleri iÃ§in test-time scaling implementasyonu
- **`requirements.txt`** - TÃ¼m gerekli Python baÄŸÄ±mlÄ±lÄ±klarÄ±
- **`setup.sh`** - Otomatik kurulum script'i
- **`.env.example`** - Ã‡evre deÄŸiÅŸkenleri ÅŸablonu
- **`CONTRIBUTING.md`** - KatkÄ±da bulunma rehberi

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Gereksinimler

Sisteminizde Python 3.7+ yÃ¼klÃ¼ olduÄŸundan emin olun.

### Kurulum

**Otomatik Kurulum (Ã–nerilen):**

```bash
# Repository'yi klonlayÄ±n
git clone https://github.com/emredeveloper/Transformers-Examples.git
cd Transformers-Examples

# Otomatik kurulum script'ini Ã§alÄ±ÅŸtÄ±rÄ±n
chmod +x setup.sh
./setup.sh --venv
```

**Manuel Kurulum:**

1. Repository'yi klonlayÄ±n:

```bash
git clone https://github.com/emredeveloper/Transformers-Examples.git
cd Transformers-Examples
```

2. Virtual environment oluÅŸturun (Ã¶nerilen):

```bash
python -m venv .venv
# Windows iÃ§in:
.venv\Scripts\activate
# Linux/Mac iÃ§in:
source .venv/bin/activate
```

3. BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin:

```bash
pip install -r requirements.txt
```

4. Ã‡evre deÄŸiÅŸkenlerini ayarlayÄ±n:

```bash
# .env.example dosyasÄ±nÄ± .env olarak kopyalayÄ±n
copy .env.example .env  # Windows
cp .env.example .env    # Linux/Mac

# .env dosyasÄ±nÄ± dÃ¼zenleyip Hugging Face token'Ä±nÄ±zÄ± ekleyin
```

## ğŸ“– KullanÄ±m Ã–rnekleri

### RoPE KarÅŸÄ±laÅŸtÄ±rmasÄ± (YENÄ°!)

```bash
cd Architecture
python partial-rope.py
```

### Temel Transformer KullanÄ±mÄ±

```bash
cd Genel-1
python app.py
```

### Vision Transformers

```bash
cd "Vision Transformers"
jupyter notebook sglip2.ipynb
```

### Multimodal Ã–rnekler

```bash
cd "Multi Modal"
python basic-multimodal.py
```

### LLaMA Modeli

```bash
cd llama
python run_cpu.py
```

### Tokenizer EÄŸitimi

```bash
cd Tokenizer
python tokenizer.py
```

### Test-Time Scaling

```bash
python test-time-scaling.py
```

## âš™ï¸ KonfigÃ¼rasyon

BirÃ§ok Ã¶rnek Ã§evre deÄŸiÅŸkenleri aracÄ±lÄ±ÄŸÄ±yla konfigÃ¼rasyonu destekler:

- `HUGGINGFACE_TOKEN`: Hugging Face API token'Ä±nÄ±z
- `CUDA_VISIBLE_DEVICES`: GPU cihaz seÃ§imi
- `MODEL_CACHE_DIR`: Ä°ndirilen modeller iÃ§in cache dizini

## ğŸ“ Ã–rneklere Genel BakÄ±ÅŸ

### Dil Modelleri

- GPT-2 konfigÃ¼rasyonu ve fine-tuning
- DeepSeek transformer implementasyonlarÄ±
- Qwen 3 model kullanÄ±mÄ±
- Test-time scaling teknikleri
- RoPE (Rotary Position Embedding) karÅŸÄ±laÅŸtÄ±rmalarÄ±

### Vision Modelleri

- Vision Transformer (ViT) implementasyonlarÄ±
- SGLIP-2 multimodal anlayÄ±ÅŸ
- GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma Ã¶rnekleri

### Multimodal Modeller

- Video, ses ve metin iÅŸleme
- Cross-modal attention mekanizmalarÄ±
- Multimodal fusion teknikleri

### Zaman Serileri

- Transformer tabanlÄ± zaman serisi tahmini
- Sequence-to-sequence modelleme

### Ä°leri Teknikler

- Mixture of Experts (MoE)
- Cross-attention mekanizmalarÄ±
- Ã–zel tokenization stratejileri
- Model optimizasyon teknikleri
- Partial RoPE implementasyonlarÄ±

## ğŸ”§ Yeni Ã–zellikler

### Architecture Dizini

Bu dizin transformer mimarisi ile ilgili geliÅŸmiÅŸ Ã¶rnekler iÃ§erir:

- **`partial-rope.py`**: Partial RoPE vs Full RoPE performans karÅŸÄ±laÅŸtÄ±rmasÄ±
- DetaylÄ± benchmark sonuÃ§larÄ± ve gÃ¶rselleÅŸtirmeler
- Bellek kullanÄ±mÄ± analizleri
- Ablasyon Ã§alÄ±ÅŸmalarÄ±

## ğŸ¤ KatkÄ±da Bulunma

KatkÄ±lar memnuniyetle karÅŸÄ±lanÄ±r! LÃ¼tfen Pull Request gÃ¶ndermekten Ã§ekinmeyin. BÃ¼yÃ¼k deÄŸiÅŸiklikler iÃ§in, Ã¶nce ne deÄŸiÅŸtirmek istediÄŸinizi tartÄ±ÅŸmak Ã¼zere bir issue aÃ§Ä±n.

DetaylÄ± bilgi iÃ§in `CONTRIBUTING.md` dosyasÄ±nÄ± kontrol edin.

## ğŸ“„ Lisans

Bu proje aÃ§Ä±k kaynaklÄ±dÄ±r ve MIT LisansÄ± altÄ±nda mevcuttur.

## ğŸ” Notlar

- BazÄ± Ã¶rnekler Ã¶zel model eriÅŸim izinleri gerektirir
- BÃ¼yÃ¼k modelleri Ã§alÄ±ÅŸtÄ±rmak iÃ§in GPU Ã¶nerilir
- Belirli gereksinimler iÃ§in bireysel dizin README dosyalarÄ±nÄ± kontrol edin
- Hugging Face modelleri iÃ§in uygun kimlik doÄŸrulamasÄ± ayarladÄ±ÄŸÄ±nÄ±zdan emin olun
- `.env` dosyasÄ±nÄ± oluÅŸturmayÄ± ve API token'larÄ±nÄ±zÄ± eklemeyi unutmayÄ±n

## ğŸ› Sorun Giderme

### YaygÄ±n Sorunlar

1. **Import hatalarÄ±**: TÃ¼m baÄŸÄ±mlÄ±lÄ±klarÄ±n yÃ¼klÃ¼ olduÄŸundan emin olun
2. **CUDA hatalarÄ±**: GPU kullanÄ±labilirliÄŸini ve CUDA kurulumunu kontrol edin
3. **Model eriÅŸimi**: Ã–zel modeller iÃ§in uygun izinlere sahip olduÄŸunuzdan emin olun
4. **Bellek hatalarÄ±**: Daha kÃ¼Ã§Ã¼k batch boyutlarÄ± veya model varyantlarÄ± kullanmayÄ± dÃ¼ÅŸÃ¼nÃ¼n
5. **Token hatalarÄ±**: `.env` dosyasÄ±nda Hugging Face token'Ä±nÄ±zÄ±n doÄŸru ayarlandÄ±ÄŸÄ±ndan emin olun

Daha detaylÄ± yardÄ±m iÃ§in, lÃ¼tfen belirli dizin belgelerini kontrol edin veya bir issue aÃ§Ä±n.

## ğŸ“Š Benchmark SonuÃ§larÄ±

Repository, Ã§eÅŸitli transformer varyantlarÄ± iÃ§in performans karÅŸÄ±laÅŸtÄ±rmalarÄ± iÃ§erir:

- RoPE implementasyonlarÄ± arasÄ±ndaki hÄ±z ve doÄŸruluk karÅŸÄ±laÅŸtÄ±rmalarÄ±
- MMLU benchmark sonuÃ§larÄ± (archive/ dizininde)
- Model optimizasyon teknikleri analizi

DetaylÄ± sonuÃ§lar iÃ§in `Architecture/` dizinini ve generate edilen PNG dosyalarÄ±nÄ± kontrol edin. 
